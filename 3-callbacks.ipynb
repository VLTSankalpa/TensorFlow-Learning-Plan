{"cells":[{"cell_type":"markdown","metadata":{"id":"vBNo9JrZIYG6"},"source":["# Callbacks\n","\n","A callback in TensorFlow is a function that is executed at certain stages of the training process, such as at the end of every epoch. They are used to perform actions during training, such as saving model weights, updating learning rates, stopping training early, or logging metrics.\n","\n","Here are a few important uses of callbacks:\n","\n","1. **Model Checkpointing**: This saves the model's weights at different points during training. It's useful because if a long running training process gets interrupted, you can resume from the last saved state.\n","2. **Learning Rate Scheduling**: This adjusts the learning rate during training. For example, you might want to decrease the learning rate over time.\n","3. **Early Stopping**: This stops training when the model's performance on a validation set stops improving. It's useful to prevent overfitting - when the model starts to learn the training data too well and performs poorly on unseen data.\n","\n","### **Model Checkpointing:**\n","\n","Model checkpointing is implemented using the **`ModelCheckpoint`** callback. This is useful in case your training procedure gets interrupted. You can save the model or just the weights at regular intervals during training.\n","\n","```python\n","\n","checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"my_model.h5\", save_best_only=True)\n","\n","model.fit(training_images, training_labels, epochs=10,\n","          validation_data=(test_images, test_labels),\n","          callbacks=[checkpoint_cb])\n","\n","```\n","\n","In this example, **`ModelCheckpoint`** will save the weights of the model in a file named \"my_model.h5\" at the end of each epoch. The **`save_best_only=True`** argument means it will only save the model when its performance on the validation set is the best so far.\n","\n","### **Learning Rate Scheduling:**\n","\n","You can adjust the learning rate during training by using the **`LearningRateScheduler`** callback. This can help the model converge faster or achieve a better result.\n","\n","```python\n","\n","def scheduler(epoch, lr):\n","  if epoch < 10:\n","    return lr\n","  else:\n","    return lr * tf.math.exp(-0.1)\n","\n","lr_schedule_cb = tf.keras.callbacks.LearningRateScheduler(scheduler)\n","\n","model.fit(training_images, training_labels, epochs=20,\n","          callbacks=[lr_schedule_cb])\n","\n","```\n","\n","In this example, the learning rate will stay the same for the first 10 epochs, and then it will exponentially decay every epoch after that.\n","\n","### **Early Stopping: P**atience\n","\n","You can stop training when a monitored metric has stopped improving by using the **`EarlyStopping`** callback. This can prevent overfitting by not allowing the model to learn the training data too well.\n","\n","```python\n","\n","early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n","\n","model.fit(training_images, training_labels, epochs=100,\n","          validation_data=(test_images, test_labels),\n","          callbacks=[early_stopping_cb])\n","\n","```\n","\n","In this example, training will stop when the validation loss doesn't improve for 10 epochs. The **`restore_best_weights=True`** argument means the model will keep the weights from the epoch with the best monitored metric, which in this case is the validation loss.\n","\n","### **Early Stopping: T**arget accuracy or loss\n","\n","Here's an example of a simple callback that stops training when it reaches a certain accuracy:\n","\n","```python\n","class myCallback(tf.keras.callbacks.Callback):\n","  def on_epoch_end(self, epoch, logs={}):\n","    if(logs.get('accuracy')>0.9):\n","      print(\"\\nReached 90% accuracy so cancelling training!\")\n","      self.model.stop_training = True\n","\n","callbacks = myCallback()\n","\n","model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks])\n","\n","```\n","\n","In this example, the **`on_epoch_end`** function is called at the end of each epoch, and if the accuracy at that point is above 90%, it stops the training."]},{"cell_type":"markdown","metadata":{"id":"Mcwrn9AKKVb8"},"source":["## Load and Normalize the Fashion MNIST dataset\n","\n","Like the previous lab, you will use the Fashion MNIST dataset again for this exercise. And also as mentioned before, you will normalize the pixel values to help optimize the training."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8LTaefqDJMIn"},"outputs":[],"source":["import tensorflow as tf\n","\n","# Instantiate the dataset API\n","fmnist = tf.keras.datasets.fashion_mnist\n","\n","# Load the dataset\n","(x_train, y_train),(x_test, y_test) = fmnist.load_data()\n","\n","# Normalize the pixel values\n","x_train, x_test = x_train / 255.0, x_test / 255.0"]},{"cell_type":"markdown","metadata":{"id":"Ia2OadhALJjS"},"source":["## Creating a Callback class\n","\n","You can create a callback by defining a class that inherits the [tf.keras.callbacks.Callback](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback) base class. From there, you can define available methods to set where the callback will be executed. For instance below, you will use the [on_epoch_end()](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback#on_epoch_end) method to check the loss at each training epoch."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uuRmQZWVJAJH"},"outputs":[],"source":["class myCallback(tf.keras.callbacks.Callback):\n","  def on_epoch_end(self, epoch, logs={}):\n","    # Check accuracy\n","    if(logs.get('loss') < 0.4):\n","\n","      # Stop if threshold is met\n","      print(\"\\nLoss is lower than 0.4 so cancelling training!\")\n","      self.model.stop_training = True\n","\n","# Instantiate class\n","callbacks = myCallback()"]},{"cell_type":"markdown","metadata":{"id":"4xlXeLkFeMn8"},"source":["## Define and compile the model\n","\n","Next, you will define and compile the model. The architecture will be similar to the one you built in the previous lab. Afterwards, you will set the optimizer, loss, and metrics that you will use for training."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7JXxMg3TpzER"},"outputs":[],"source":["# Define the model\n","model = tf.keras.models.Sequential([\n","  tf.keras.layers.Flatten(input_shape=(28, 28)),\n","  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n","  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n","])\n","\n","# Compile the model\n","model.compile(optimizer=tf.optimizers.Adam(),\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n"]},{"cell_type":"markdown","metadata":{"id":"6eLe4cPZe-ui"},"source":["## Train the model\n","\n","Now you are ready to train the model. To set the callback, simply set the `callbacks` parameter to the `myCallback` instance you declared before. Run the cell below and observe what happens."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nLXTB32de3_e"},"outputs":[],"source":["# Train the model with a callback\n","model.fit(x_train, y_train, epochs=10, callbacks=[callbacks])"]},{"cell_type":"markdown","metadata":{"id":"fGBSkRQPff93"},"source":["You will notice that the training does not need to complete all 10 epochs. By having a callback at each end of the epoch, it is able to check the training parameters and compare if it meets the threshold you set in the function definition. In this case, it will simply stop when the loss falls below `0.40` after the current epoch.\n","\n","*Optional Challenge: Modify the code to make the training stop when the accuracy metric exceeds 60%.*\n","\n","That concludes this simple exercise on callbacks!"]}],"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"https://github.com/https-deeplearning-ai/tensorflow-1-public/blob/adding_C1/C1/W2/ungraded_labs/C1_W2_Lab_2_callbacks.ipynb","timestamp":1638884482962}],"toc_visible":true,"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}